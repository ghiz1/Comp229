{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'facedat', 'dirnames'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the umist_cropped.mat file using scipy.io\n",
    "mat = scipy.io.loadmat('umist_cropped.mat')\n",
    "\n",
    "# Display the keys of the loaded .mat file to understand its structure\n",
    "mat.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9  ...  10295  10296  10297  \\\n",
      "0  233  234  234  233  234  232  232  168   99   78  ...    154    151    147   \n",
      "1  234  234  234  234  233  232  202   98   79   77  ...    154    150    147   \n",
      "2  234  234  234  234  233  230  225  109   85   84  ...    174    168    164   \n",
      "3  234  234  234  234  234  234  234  232  229  205  ...    168    162    157   \n",
      "4  234  234  234  234  234  234  234  234  229  211  ...    176    170    164   \n",
      "\n",
      "   10298  10299  10300  10301  10302  10303  label  \n",
      "0    143    140    141    141    140    136     1a  \n",
      "1    141    140    137    138    137    137     1a  \n",
      "2    157    152    151    148    145    145     1a  \n",
      "3    155    150    144    144    142    143     1a  \n",
      "4    162    157    152    150    148    148     1a  \n",
      "\n",
      "[5 rows x 10305 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the facedat and dirnames\n",
    "facedat = mat['facedat']\n",
    "dirnames = mat['dirnames']\n",
    "\n",
    "# Prepare a list to store flattened images and corresponding labels\n",
    "image_list = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over each entry in facedat and corresponding label in dirnames\n",
    "for i in range(facedat.shape[1]):  # facedat[0, i] gives each set of images for a person\n",
    "    image_set = facedat[0, i]      # Extract the 3D array of images for this person\n",
    "    num_images = image_set.shape[-1]  # Get the number of images in this set\n",
    "\n",
    "    for j in range(num_images):       # Loop over each image for the person\n",
    "        image = image_set[:, :, j]    # Select individual 2D image\n",
    "        image_flat = image.flatten()  # Flatten the image\n",
    "\n",
    "        # Append flattened image to the list\n",
    "        image_list.append(image_flat)\n",
    "\n",
    "        # Extract label ('1a', '1b', ...) as a string and assign to each image\n",
    "        labels.append(dirnames[0, i][0])\n",
    "\n",
    "# Create a DataFrame with flattened images\n",
    "data_group2 = pd.DataFrame(image_list)\n",
    "\n",
    "# Add labels as a new column in the DataFrame\n",
    "data_group2['label'] = labels\n",
    "\n",
    "# Display the first few rows to verify the DataFrame structure\n",
    "print(data_group2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepate the features and the target variable\n",
    "data_group2_features = data_group2.iloc[:, :-1]\n",
    "data_group2_target = data_group2.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 10\n"
     ]
    }
   ],
   "source": [
    "# Check for Duplicate Entries\n",
    "# Ensure there are no duplicate entries in the dataset that could bias the model.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicate_count = data_group2.duplicated().sum()\n",
    "print(f\"Number of duplicate entries: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries before removing: 10\n",
      "Duplicate entries removed and data updated.\n",
      "data shape (565, 10305)\n",
      "duplicate entries after removing 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate entries\n",
    "duplicate_count = data_group2.duplicated().sum()\n",
    "print(f\"Number of duplicate entries before removing: {duplicate_count}\")\n",
    "# Remove duplicates if any\n",
    "if duplicate_count > 0:\n",
    "    data_group2 = data_group2.drop_duplicates()\n",
    "    data_group2_features = data_group2.iloc[:, :-1].values / 255.0\n",
    "    data_group2_target = data_group2.iloc[:, -1].values\n",
    "    X_images = data_group2_features.reshape(-1, 112, 92, 1)\n",
    "    print(\"Duplicate entries removed and data updated.\")\n",
    "else:\n",
    "    print(\"No duplicate entries found.\")\n",
    "\n",
    "#shape of the data\n",
    "print('data shape', data_group2.shape)\n",
    "\n",
    "#count the duplicate entries\n",
    "print('duplicate entries after removing', data_group2.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ezzar\\anaconda3\\envs\\Semester2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation setup completed.\n",
      "Target image count for each label: 48\n",
      "Current count for label '1a': 38\n",
      "Generating 10 additional images for label '1a'\n",
      "Current count for label '1b': 25\n",
      "Generating 23 additional images for label '1b'\n",
      "Current count for label '1c': 26\n",
      "Generating 22 additional images for label '1c'\n",
      "Current count for label '1d': 24\n",
      "Generating 24 additional images for label '1d'\n",
      "Current count for label '1e': 26\n",
      "Generating 22 additional images for label '1e'\n",
      "Current count for label '1f': 23\n",
      "Generating 25 additional images for label '1f'\n",
      "Current count for label '1g': 19\n",
      "Generating 29 additional images for label '1g'\n",
      "Current count for label '1h': 22\n",
      "Generating 26 additional images for label '1h'\n",
      "Current count for label '1i': 20\n",
      "Generating 28 additional images for label '1i'\n",
      "Current count for label '1j': 32\n",
      "Generating 16 additional images for label '1j'\n",
      "Current count for label '1k': 34\n",
      "Generating 14 additional images for label '1k'\n",
      "Current count for label '1l': 34\n",
      "Generating 14 additional images for label '1l'\n",
      "Current count for label '1m': 26\n",
      "Generating 22 additional images for label '1m'\n",
      "Current count for label '1n': 30\n",
      "Generating 18 additional images for label '1n'\n",
      "Current count for label '1o': 19\n",
      "Generating 29 additional images for label '1o'\n",
      "Current count for label '1p': 26\n",
      "Generating 22 additional images for label '1p'\n",
      "Current count for label '1q': 26\n",
      "Generating 22 additional images for label '1q'\n",
      "Current count for label '1r': 33\n",
      "Generating 15 additional images for label '1r'\n",
      "Current count for label '1s': 48\n",
      "Current count for label '1t': 34\n",
      "Generating 14 additional images for label '1t'\n",
      "label\n",
      "1a    48\n",
      "1b    48\n",
      "1s    48\n",
      "1r    48\n",
      "1q    48\n",
      "1p    48\n",
      "1o    48\n",
      "1n    48\n",
      "1m    48\n",
      "1l    48\n",
      "1k    48\n",
      "1j    48\n",
      "1i    48\n",
      "1h    48\n",
      "1g    48\n",
      "1f    48\n",
      "1e    48\n",
      "1d    48\n",
      "1c    48\n",
      "1t    48\n",
      "Name: count, dtype: int64\n",
      "Duplicate values after augmentation: 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# !pip install albumentations\n",
    "\n",
    "# Data Augmentation using Albumentations\n",
    "# Set up data augmentation using Albumentations to enhance the diversity of the training dataset.\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "# Data Augmentation setup\n",
    "transform = A.Compose([\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.GaussNoise(p=0.2)])\n",
    "\n",
    "# Note: Albumentations will be applied during training\n",
    "print(\"Data augmentation setup completed.\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Determine the maximum count to balance the dataset\n",
    "target_count = data_group2['label'].value_counts().max()\n",
    "print(\"Target image count for each label:\", target_count)\n",
    "\n",
    "# Balance the dataset by augmenting images\n",
    "balanced_images = []\n",
    "balanced_labels = []\n",
    "\n",
    "# Create a set to track already added images (flattened version for comparison)\n",
    "added_images = set()\n",
    "\n",
    "# Iterate over each unique label to augment images where needed\n",
    "for label in data_group2['label'].unique():\n",
    "    label_images = data_group2[data_group2['label'] == label].drop(columns=['label']).values\n",
    "    label_count = label_images.shape[0]\n",
    "    print(f\"Current count for label '{label}': {label_count}\")\n",
    "\n",
    "    # Reshape each flattened image back to original dimensions\n",
    "    reshaped_images = [img.reshape(112, 92, 1) for img in label_images]  # Assuming 112x92 image size\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    reshaped_images = np.array(reshaped_images)\n",
    "\n",
    "    # Add original images to balanced dataset, check for uniqueness\n",
    "    for img in reshaped_images:\n",
    "        img_flattened = img.flatten()\n",
    "        if tuple(img_flattened) not in added_images:  # Check if image is not already added\n",
    "            balanced_images.append(img_flattened)\n",
    "            balanced_labels.append(label)\n",
    "            added_images.add(tuple(img_flattened))  # Mark image as added\n",
    "\n",
    "    # Generate augmented images if current count is less than target\n",
    "    if label_count < target_count:\n",
    "        n_needed = target_count - label_count\n",
    "        print(f\"Generating {n_needed} additional images for label '{label}'\")\n",
    "\n",
    "        # Randomly select and augment images until we reach the required number\n",
    "        for _ in range(n_needed):\n",
    "            while True:  # Continue until a unique augmented image is found\n",
    "                img = reshaped_images[np.random.choice(len(reshaped_images))]  # Randomly select an image\n",
    "                augmented = transform(image=img.squeeze())['image']\n",
    "                augmented_img = augmented.reshape(112, 92)\n",
    "\n",
    "                # Flatten the augmented image for uniqueness check\n",
    "                augmented_img_flattened = augmented_img.flatten()\n",
    "\n",
    "                # Check if the augmented image has already been added\n",
    "                if tuple(augmented_img_flattened) not in added_images:\n",
    "                    balanced_images.append(augmented_img_flattened)\n",
    "                    balanced_labels.append(label)\n",
    "                    added_images.add(tuple(augmented_img_flattened))  # Mark as added\n",
    "                    break  # Break out of the loop when a unique image is found\n",
    "\n",
    "# Create a new balanced DataFrame\n",
    "balanced_data_group2 = pd.DataFrame(balanced_images)\n",
    "balanced_data_group2['label'] = balanced_labels\n",
    "\n",
    "# Verify the balancing\n",
    "print(balanced_data_group2['label'].value_counts())\n",
    "\n",
    "# Check for duplicates after augmentation\n",
    "print('Duplicate values after augmentation:', balanced_data_group2.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1         2         3         4         5         6      \\\n",
      "0  0.913725  0.917647  0.917647  0.913725  0.917647  0.909804  0.909804   \n",
      "1  0.917647  0.917647  0.917647  0.917647  0.913725  0.909804  0.792157   \n",
      "2  0.917647  0.917647  0.917647  0.917647  0.913725  0.901961  0.882353   \n",
      "3  0.917647  0.917647  0.917647  0.917647  0.917647  0.917647  0.917647   \n",
      "4  0.917647  0.917647  0.917647  0.917647  0.917647  0.917647  0.917647   \n",
      "\n",
      "      7         8         9      ...     10294     10295     10296     10297  \\\n",
      "0  0.658824  0.388235  0.305882  ...  0.615686  0.603922  0.592157  0.576471   \n",
      "1  0.384314  0.309804  0.301961  ...  0.619608  0.603922  0.588235  0.576471   \n",
      "2  0.427451  0.333333  0.329412  ...  0.705882  0.682353  0.658824  0.643137   \n",
      "3  0.909804  0.898039  0.803922  ...  0.682353  0.658824  0.635294  0.615686   \n",
      "4  0.917647  0.898039  0.827451  ...  0.729412  0.690196  0.666667  0.643137   \n",
      "\n",
      "      10298     10299     10300     10301     10302     10303  \n",
      "0  0.560784  0.549020  0.552941  0.552941  0.549020  0.533333  \n",
      "1  0.552941  0.549020  0.537255  0.541176  0.537255  0.537255  \n",
      "2  0.615686  0.596078  0.592157  0.580392  0.568627  0.568627  \n",
      "3  0.607843  0.588235  0.564706  0.564706  0.556863  0.560784  \n",
      "4  0.635294  0.615686  0.596078  0.588235  0.580392  0.580392  \n",
      "\n",
      "[5 rows x 10304 columns]\n",
      "min 0.0\n",
      "max 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#sepate the features and the target variable\n",
    "data_balanced_group2_features = balanced_data_group2.iloc[:, :-1]\n",
    "data_balanced_group2_target = balanced_data_group2.iloc[:, -1]\n",
    "# Normalize Pixel Values\n",
    "# Normalize the pixel values to a range of [0, 1] to facilitate faster and more effective training.\n",
    "data_balanced_group2_features = data_balanced_group2_features / 255.0\n",
    "print(data_balanced_group2_features.head())\n",
    "#min max of all the columns except the label column\n",
    "print('min', data_balanced_group2_features.iloc[:, :-1].min().min())\n",
    "print('max', data_balanced_group2_features.iloc[:, :-1].max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (576, 10304) (576,)\n",
      "Validation set shape: (192, 10304) (192,)\n",
      "Test set shape: (192, 10304) (192,)\n"
     ]
    }
   ],
   "source": [
    "# Stratified Sampling\n",
    "# Split the dataset into training, validation, and testing sets using stratified sampling to maintain class distribution across all subsets.\n",
    "\n",
    "#dataframe to array \n",
    "data_balanced_group2_featuress = data_balanced_group2_features.values\n",
    "data_balanced_group2_targets = data_balanced_group2_target.values \n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Initialize StratifiedShuffleSplit for the first split (train + temp) 60% train, 40% temp\n",
    "s1 = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=44)\n",
    "for train_index, temp_index in s1.split(data_balanced_group2_featuress, data_balanced_group2_targets):\n",
    "    X_train, X_temp = data_balanced_group2_featuress[train_index], data_balanced_group2_featuress[temp_index]\n",
    "    y_train, y_temp = data_balanced_group2_targets[train_index], data_balanced_group2_targets[temp_index]\n",
    "\n",
    "# Initialize StratifiedShuffleSplit for the second split (validation/test)\n",
    "s2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=44)\n",
    "for val_index, test_index in s2.split(X_temp, y_temp):\n",
    "    X_val, X_test = X_temp[val_index], X_temp[test_index]\n",
    "    y_val, y_test = y_temp[val_index], y_temp[test_index]\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_group2 = le.fit_transform(y_train)\n",
    "y_val_group2 = le.transform(y_val)\n",
    "y_test_group2 = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components selected: 310\n",
      "Original number of features: (576, 10304)\n",
      "Reduced number of features after PCA: (576, 310)\n",
      "PCA transformed training set shape: (576, 310)\n",
      "PCA transformed validation set shape: (192, 310)\n",
      "PCA transformed test set shape: (192, 310)\n"
     ]
    }
   ],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "# Apply PCA to the Training Set\n",
    "# Apply PCA to reduce dimensionality and capture the most significant variance in the training data.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA with 99% variance explained\n",
    "pca = PCA(n_components=0.99, svd_solver='full', random_state=44)\n",
    "\n",
    "# Fit PCA to the training data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Check the number of components selected\n",
    "n_components = pca.n_components_\n",
    "print(f\"Number of components selected: {n_components}\")\n",
    "#check the variance ratio of the components percentage of variance explained by all component\n",
    "#print('explained variance ratio:', pca.explained_variance_ratio_)\n",
    "#check the variance of the components\n",
    "#print('explained variance:', pca.explained_variance_)\n",
    "\n",
    "\n",
    "# Apply PCA to the Validation and Test Sets\n",
    "# Apply the same PCA transformation to the validation and test sets to maintain consistency across all datasets.\n",
    "print(f\"Original number of features: {X_train.shape}\")\n",
    "print(f\"Reduced number of features after PCA: {X_train_pca.shape}\")\n",
    "\n",
    "# Transform the validation and test sets\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Check the shape of the transformed datasets\n",
    "print(\"PCA transformed training set shape:\", X_train_pca.shape)\n",
    "print(\"PCA transformed validation set shape:\", X_val_pca.shape)\n",
    "print(\"PCA transformed test set shape:\", X_test_pca.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save as .npy\n",
    "np.save('X_train_pca.npy', X_train_pca)\n",
    "np.save('X_val_pca.npy', X_val_pca)\n",
    "np.save('y_train_group2.npy', y_train_group2)\n",
    "np.save('y_val_group2.npy', y_val_group2)\n",
    "np.save('y_test_group2.npy', y_test_group2)\n",
    "# Load it back\n",
    "X_train_pca = np.load('X_train_pca.npy')\n",
    "X_val_pca = np.load('X_val_pca.npy')\n",
    "y_train_group2 = np.load('y_train_group2.npy')\n",
    "y_val_group2 = np.load('y_val_group2.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semester2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
